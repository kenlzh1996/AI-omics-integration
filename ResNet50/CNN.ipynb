{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a9be1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as op\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from pdb import set_trace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffe6a83",
   "metadata": {},
   "source": [
    "### Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cde191c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (7700, 254)\n"
     ]
    }
   ],
   "source": [
    "# load training dataset\n",
    "train = pd.read_csv('krug_train_0425.csv')\n",
    "print(\"Shape:\", train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e98dc40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (7167, 254)\n"
     ]
    }
   ],
   "source": [
    "# excluding \"unclassified\" gene\n",
    "train = train[train['Localization']!='Unclassified']\n",
    "print(\"Shape:\", train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf2f7635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Cytosol': 3068,\n",
       "         'Secretory': 1602,\n",
       "         'Mitochondria': 508,\n",
       "         'Nuclear': 1989})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check target class and number\n",
    "Counter(train['Localization'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d78399d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns=['Unnamed: 0','Gene'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "861ac135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign independent variables as X and target as Y\n",
    "X = train.drop(columns='Localization')\n",
    "Y = train['Localization']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce7446ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CPT000814_mrna</th>\n",
       "      <th>CPT000814_prot</th>\n",
       "      <th>CPT001846_mrna</th>\n",
       "      <th>CPT001846_prot</th>\n",
       "      <th>Hydropathicity</th>\n",
       "      <th>Hydrophobic</th>\n",
       "      <th>Length</th>\n",
       "      <th>Mass</th>\n",
       "      <th>Negative Charged</th>\n",
       "      <th>Polar</th>\n",
       "      <th>...</th>\n",
       "      <th>X21BR001_mrna</th>\n",
       "      <th>X21BR001_prot</th>\n",
       "      <th>X21BR002_mrna</th>\n",
       "      <th>X21BR002_prot</th>\n",
       "      <th>X21BR010_mrna</th>\n",
       "      <th>X21BR010_prot</th>\n",
       "      <th>X22BR005_mrna</th>\n",
       "      <th>X22BR005_prot</th>\n",
       "      <th>X22BR006_mrna</th>\n",
       "      <th>X22BR006_prot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.096662</td>\n",
       "      <td>-0.987411</td>\n",
       "      <td>0.963136</td>\n",
       "      <td>0.510677</td>\n",
       "      <td>-107.2</td>\n",
       "      <td>253</td>\n",
       "      <td>495</td>\n",
       "      <td>54254</td>\n",
       "      <td>59</td>\n",
       "      <td>123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220329</td>\n",
       "      <td>-0.980020</td>\n",
       "      <td>-2.368934</td>\n",
       "      <td>-1.496265</td>\n",
       "      <td>-1.030711</td>\n",
       "      <td>0.338161</td>\n",
       "      <td>-1.473182</td>\n",
       "      <td>-0.142581</td>\n",
       "      <td>-0.497003</td>\n",
       "      <td>-0.135263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.807365</td>\n",
       "      <td>1.661429</td>\n",
       "      <td>-1.073807</td>\n",
       "      <td>-0.544436</td>\n",
       "      <td>-229.2</td>\n",
       "      <td>694</td>\n",
       "      <td>1454</td>\n",
       "      <td>161107</td>\n",
       "      <td>147</td>\n",
       "      <td>469</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.064193</td>\n",
       "      <td>-0.478182</td>\n",
       "      <td>-1.748910</td>\n",
       "      <td>-0.505438</td>\n",
       "      <td>-0.380101</td>\n",
       "      <td>-0.723629</td>\n",
       "      <td>0.159810</td>\n",
       "      <td>-1.589012</td>\n",
       "      <td>-0.752751</td>\n",
       "      <td>-1.208401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.921069</td>\n",
       "      <td>2.207973</td>\n",
       "      <td>0.149664</td>\n",
       "      <td>1.134415</td>\n",
       "      <td>-45.9</td>\n",
       "      <td>281</td>\n",
       "      <td>546</td>\n",
       "      <td>59574</td>\n",
       "      <td>44</td>\n",
       "      <td>159</td>\n",
       "      <td>...</td>\n",
       "      <td>1.795527</td>\n",
       "      <td>1.926580</td>\n",
       "      <td>1.847351</td>\n",
       "      <td>0.904696</td>\n",
       "      <td>-1.521417</td>\n",
       "      <td>-0.457078</td>\n",
       "      <td>0.142118</td>\n",
       "      <td>0.307630</td>\n",
       "      <td>1.043184</td>\n",
       "      <td>0.946137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.545107</td>\n",
       "      <td>-0.245457</td>\n",
       "      <td>-0.996630</td>\n",
       "      <td>-0.604077</td>\n",
       "      <td>-101.0</td>\n",
       "      <td>332</td>\n",
       "      <td>672</td>\n",
       "      <td>75144</td>\n",
       "      <td>81</td>\n",
       "      <td>173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.622088</td>\n",
       "      <td>-0.582726</td>\n",
       "      <td>0.932254</td>\n",
       "      <td>-1.483978</td>\n",
       "      <td>-2.739788</td>\n",
       "      <td>-0.819272</td>\n",
       "      <td>-0.259954</td>\n",
       "      <td>-0.198655</td>\n",
       "      <td>0.065907</td>\n",
       "      <td>-0.024713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.629199</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.132385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-56.3</td>\n",
       "      <td>219</td>\n",
       "      <td>425</td>\n",
       "      <td>47352</td>\n",
       "      <td>43</td>\n",
       "      <td>114</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.523778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.867375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.245352</td>\n",
       "      <td>-0.381538</td>\n",
       "      <td>-0.988437</td>\n",
       "      <td>-0.966856</td>\n",
       "      <td>-0.323424</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7695</th>\n",
       "      <td>3.211827</td>\n",
       "      <td>-1.628449</td>\n",
       "      <td>-0.059647</td>\n",
       "      <td>-1.627513</td>\n",
       "      <td>-352.3</td>\n",
       "      <td>435</td>\n",
       "      <td>858</td>\n",
       "      <td>89988</td>\n",
       "      <td>76</td>\n",
       "      <td>231</td>\n",
       "      <td>...</td>\n",
       "      <td>2.775597</td>\n",
       "      <td>2.207727</td>\n",
       "      <td>3.158407</td>\n",
       "      <td>-0.137500</td>\n",
       "      <td>-0.027997</td>\n",
       "      <td>-1.499737</td>\n",
       "      <td>-1.275230</td>\n",
       "      <td>1.302235</td>\n",
       "      <td>-0.259425</td>\n",
       "      <td>1.094237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7696</th>\n",
       "      <td>-1.569251</td>\n",
       "      <td>1.409412</td>\n",
       "      <td>0.181830</td>\n",
       "      <td>0.078361</td>\n",
       "      <td>-52.9</td>\n",
       "      <td>354</td>\n",
       "      <td>744</td>\n",
       "      <td>83921</td>\n",
       "      <td>82</td>\n",
       "      <td>205</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.139624</td>\n",
       "      <td>0.545419</td>\n",
       "      <td>-0.709049</td>\n",
       "      <td>0.729573</td>\n",
       "      <td>1.276216</td>\n",
       "      <td>0.044586</td>\n",
       "      <td>-0.453202</td>\n",
       "      <td>-1.780543</td>\n",
       "      <td>2.019090</td>\n",
       "      <td>-0.274506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7697</th>\n",
       "      <td>1.101153</td>\n",
       "      <td>-1.176195</td>\n",
       "      <td>2.392994</td>\n",
       "      <td>2.096937</td>\n",
       "      <td>-360.6</td>\n",
       "      <td>298</td>\n",
       "      <td>572</td>\n",
       "      <td>61277</td>\n",
       "      <td>55</td>\n",
       "      <td>155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.649147</td>\n",
       "      <td>-1.069202</td>\n",
       "      <td>1.366297</td>\n",
       "      <td>-0.015496</td>\n",
       "      <td>-1.157026</td>\n",
       "      <td>0.212588</td>\n",
       "      <td>-1.024858</td>\n",
       "      <td>-0.008350</td>\n",
       "      <td>-2.017560</td>\n",
       "      <td>2.044309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7698</th>\n",
       "      <td>0.456382</td>\n",
       "      <td>-2.011132</td>\n",
       "      <td>-0.510165</td>\n",
       "      <td>-0.237296</td>\n",
       "      <td>-699.0</td>\n",
       "      <td>1359</td>\n",
       "      <td>2961</td>\n",
       "      <td>331075</td>\n",
       "      <td>384</td>\n",
       "      <td>826</td>\n",
       "      <td>...</td>\n",
       "      <td>2.183494</td>\n",
       "      <td>2.197884</td>\n",
       "      <td>1.692770</td>\n",
       "      <td>0.630830</td>\n",
       "      <td>-1.225778</td>\n",
       "      <td>0.084463</td>\n",
       "      <td>-0.924131</td>\n",
       "      <td>-0.376934</td>\n",
       "      <td>-6.868664</td>\n",
       "      <td>2.309742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7699</th>\n",
       "      <td>0.408551</td>\n",
       "      <td>1.486307</td>\n",
       "      <td>-0.085464</td>\n",
       "      <td>-0.022778</td>\n",
       "      <td>-851.9</td>\n",
       "      <td>323</td>\n",
       "      <td>903</td>\n",
       "      <td>102023</td>\n",
       "      <td>145</td>\n",
       "      <td>294</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.286050</td>\n",
       "      <td>1.779995</td>\n",
       "      <td>-1.167547</td>\n",
       "      <td>-0.380465</td>\n",
       "      <td>1.079793</td>\n",
       "      <td>0.401717</td>\n",
       "      <td>1.253979</td>\n",
       "      <td>2.020768</td>\n",
       "      <td>-7.370398</td>\n",
       "      <td>0.807293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7167 rows × 251 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CPT000814_mrna  CPT000814_prot  CPT001846_mrna  CPT001846_prot  \\\n",
       "0           0.096662       -0.987411        0.963136        0.510677   \n",
       "2           1.807365        1.661429       -1.073807       -0.544436   \n",
       "3           0.921069        2.207973        0.149664        1.134415   \n",
       "4           0.545107       -0.245457       -0.996630       -0.604077   \n",
       "5           1.629199             NaN        1.132385             NaN   \n",
       "...              ...             ...             ...             ...   \n",
       "7695        3.211827       -1.628449       -0.059647       -1.627513   \n",
       "7696       -1.569251        1.409412        0.181830        0.078361   \n",
       "7697        1.101153       -1.176195        2.392994        2.096937   \n",
       "7698        0.456382       -2.011132       -0.510165       -0.237296   \n",
       "7699        0.408551        1.486307       -0.085464       -0.022778   \n",
       "\n",
       "      Hydropathicity  Hydrophobic  Length    Mass  Negative Charged  Polar  \\\n",
       "0             -107.2          253     495   54254                59    123   \n",
       "2             -229.2          694    1454  161107               147    469   \n",
       "3              -45.9          281     546   59574                44    159   \n",
       "4             -101.0          332     672   75144                81    173   \n",
       "5              -56.3          219     425   47352                43    114   \n",
       "...              ...          ...     ...     ...               ...    ...   \n",
       "7695          -352.3          435     858   89988                76    231   \n",
       "7696           -52.9          354     744   83921                82    205   \n",
       "7697          -360.6          298     572   61277                55    155   \n",
       "7698          -699.0         1359    2961  331075               384    826   \n",
       "7699          -851.9          323     903  102023               145    294   \n",
       "\n",
       "      ...  X21BR001_mrna  X21BR001_prot  X21BR002_mrna  X21BR002_prot  \\\n",
       "0     ...       0.220329      -0.980020      -2.368934      -1.496265   \n",
       "2     ...      -1.064193      -0.478182      -1.748910      -0.505438   \n",
       "3     ...       1.795527       1.926580       1.847351       0.904696   \n",
       "4     ...       0.622088      -0.582726       0.932254      -1.483978   \n",
       "5     ...      -1.523778            NaN      -0.867375            NaN   \n",
       "...   ...            ...            ...            ...            ...   \n",
       "7695  ...       2.775597       2.207727       3.158407      -0.137500   \n",
       "7696  ...      -1.139624       0.545419      -0.709049       0.729573   \n",
       "7697  ...       0.649147      -1.069202       1.366297      -0.015496   \n",
       "7698  ...       2.183494       2.197884       1.692770       0.630830   \n",
       "7699  ...      -1.286050       1.779995      -1.167547      -0.380465   \n",
       "\n",
       "      X21BR010_mrna  X21BR010_prot  X22BR005_mrna  X22BR005_prot  \\\n",
       "0         -1.030711       0.338161      -1.473182      -0.142581   \n",
       "2         -0.380101      -0.723629       0.159810      -1.589012   \n",
       "3         -1.521417      -0.457078       0.142118       0.307630   \n",
       "4         -2.739788      -0.819272      -0.259954      -0.198655   \n",
       "5         -0.245352      -0.381538      -0.988437      -0.966856   \n",
       "...             ...            ...            ...            ...   \n",
       "7695      -0.027997      -1.499737      -1.275230       1.302235   \n",
       "7696       1.276216       0.044586      -0.453202      -1.780543   \n",
       "7697      -1.157026       0.212588      -1.024858      -0.008350   \n",
       "7698      -1.225778       0.084463      -0.924131      -0.376934   \n",
       "7699       1.079793       0.401717       1.253979       2.020768   \n",
       "\n",
       "      X22BR006_mrna  X22BR006_prot  \n",
       "0         -0.497003      -0.135263  \n",
       "2         -0.752751      -1.208401  \n",
       "3          1.043184       0.946137  \n",
       "4          0.065907      -0.024713  \n",
       "5         -0.323424            NaN  \n",
       "...             ...            ...  \n",
       "7695      -0.259425       1.094237  \n",
       "7696       2.019090      -0.274506  \n",
       "7697      -2.017560       2.044309  \n",
       "7698      -6.868664       2.309742  \n",
       "7699      -7.370398       0.807293  \n",
       "\n",
       "[7167 rows x 251 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b89759dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode target\n",
    "Y = LabelEncoder().fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61eba551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Cytosol': 3068, 'Nuclear': 1989, 'Secretory': 1602, 'Mitochondria': 508})\n",
      "Counter({0: 3068, 2: 1989, 3: 1602, 1: 508})\n"
     ]
    }
   ],
   "source": [
    "# sanity check to see numbers match and matching with previous counter to create target dictionary\n",
    "print(Counter(train['Localization']))\n",
    "print(Counter(Y))\n",
    "target_dict = {'Cytosol':0, 'Mitochondria':1, 'Nuclear':2, 'Secretory':3, 'Unclassified':4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e18402cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-valid split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.30, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d928f5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5016\n",
      "2151\n",
      "5016\n",
      "2151\n"
     ]
    }
   ],
   "source": [
    "for i in [X_train, X_val, y_train, y_val]:\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ca8282",
   "metadata": {},
   "source": [
    "### Customized Pytorch Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbe21c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch dataset\n",
    "class LoadingDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, X, Y):\n",
    "        \"\"\"\n",
    "        X is the independent variable\n",
    "        Y is the encoded target\n",
    "        \"\"\"\n",
    "        X = X.copy()\n",
    "        self.X = X.values.astype(np.float32)\n",
    "        self.y = Y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y) # return number of rows in dependent variable\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08333ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating train and valid datasets\n",
    "train_datasets = LoadingDataset(X_train, y_train)\n",
    "valid_datasets = LoadingDataset(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d740ce7",
   "metadata": {},
   "source": [
    "### Devices (GPU/CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b5d02cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making GPU and CPU compatiable\n",
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83d6a2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a565f958",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ca9739d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db43c42",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3360013",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_cont):\n",
    "        super().__init__()\n",
    "        self.n_cont = n_cont\n",
    "        self.lin1 = nn.Linear(self.n_cont, 128)\n",
    "        self.lin2 = nn.Linear(128, 32)\n",
    "        self.lin3 = nn.Linear(32, 4)\n",
    "        #self.bn1 = nn.BatchNorm1d(self.n_cont)\n",
    "        #self.bn2 = nn.BatchNorm1d(100)\n",
    "        #self.bn3 = nn.BatchNorm1d(50)\n",
    "        #self.drops = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #x = self.bn1(x_cont)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        #x = self.drops(x)\n",
    "        #x = self.bn2(x)\n",
    "        x = F.relu(self.lin2(x))\n",
    "        #x = self.drops(x)\n",
    "        #x = self.bn3(x)\n",
    "        x = self.lin3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f967430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (lin1): Linear(in_features=251, out_features=128, bias=True)\n",
       "  (lin2): Linear(in_features=128, out_features=32, bias=True)\n",
       "  (lin3): Linear(in_features=32, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN(n_cont=len(X.columns))\n",
    "to_device(model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07957063",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ae6ded2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, lr, wd):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optim = op.Adam(parameters, lr=lr, weight_decay=wd)\n",
    "    return optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed49956e",
   "metadata": {},
   "source": [
    "### Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32c59730",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loss(model, optim, train_dl):\n",
    "    model.train()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    for x, y in train_dl:\n",
    "        batch = y.shape[0]\n",
    "        output = model(x)\n",
    "        loss = F.cross_entropy(output, y)    #loss function\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        total += batch\n",
    "        sum_loss += batch*(loss.item())\n",
    "    return sum_loss/total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ad65ed",
   "metadata": {},
   "source": [
    "### Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d342a7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_loss(model, valid_dl):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    correct = 0\n",
    "    for x, y in valid_dl:\n",
    "        current_batch_size = y.shape[0]\n",
    "        out = model(x)\n",
    "        loss = F.cross_entropy(out, y)\n",
    "        sum_loss += current_batch_size*(loss.item())\n",
    "        total += current_batch_size\n",
    "        pred = torch.max(out, 1)[1]\n",
    "        correct += (pred == y).float().sum().item()\n",
    "    return sum_loss/total, correct/total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560e996c",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8181e5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, epochs, lr, wd=0.0):\n",
    "    optim = get_optimizer(model, lr = lr, wd = wd)\n",
    "    \n",
    "    times_trained = list(range(epochs))\n",
    "    train_loss_list = []\n",
    "    accuracy = []\n",
    "    valid_loss_list = []\n",
    "    \n",
    "    for i in range(epochs): \n",
    "        loss = train_loss(model, optim, train_dl)\n",
    "        train_loss_list.append(loss)\n",
    "        print(f\"Epoch {i}, training loss: \", loss)\n",
    "        valid_loss, accur = val_loss(model, valid_dl)\n",
    "        print(\"valid loss %.3f and accuracy %.3f\" % (valid_loss, accur))\n",
    "        valid_loss_list.append(valid_loss)\n",
    "        accuracy.append(accur)\n",
    "    \n",
    "    # visualize\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(times_trained, train_loss_list, label='Training loss') \n",
    "    plt.plot(times_trained, valid_loss_list, label='Validation loss')\n",
    "    #plt.xlabel('Epochs')\n",
    "    plt.ylabel(\"Training & Validation loss\")\n",
    "    \n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(times_trained, accuracy, label='Accuracy')  \n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb21ed04",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "47b34e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_dl = DataLoader(train_datasets, batch_size=batch_size,shuffle=True)\n",
    "valid_dl = DataLoader(valid_datasets, batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "227dfe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "valid_dl = DeviceDataLoader(valid_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9048d097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 1, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 2, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 3, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 4, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 5, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 6, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 7, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 8, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 9, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 10, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 11, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 12, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 13, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 14, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 15, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 16, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 17, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 18, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 19, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 20, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 21, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 22, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 23, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 24, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 25, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 26, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 27, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 28, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 29, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 30, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 31, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 32, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 33, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 34, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 35, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 36, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 37, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 38, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 39, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 40, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 41, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 42, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 43, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 44, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 45, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 46, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 47, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 48, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 49, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 50, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 51, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 52, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 53, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 54, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 55, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 56, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 57, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 58, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 59, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 60, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 61, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 62, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 63, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 64, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 65, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 66, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 67, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 68, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 69, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 70, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 71, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 72, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 73, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 74, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 75, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 76, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 77, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 78, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 79, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 80, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 81, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 82, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 83, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 84, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 85, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 86, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 87, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 88, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 89, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 90, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 91, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 92, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 93, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 94, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 95, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 96, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 97, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 98, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 99, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 100, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 101, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 102, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 103, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 104, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 105, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 106, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 107, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 108, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 109, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 110, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 111, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 112, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 113, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 114, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 115, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 116, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 117, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 118, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 119, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 120, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 121, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 122, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 123, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 124, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 125, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 126, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 127, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 129, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 130, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 131, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 132, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 133, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 134, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 135, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 136, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 137, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 138, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 139, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 140, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 141, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 142, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 143, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 144, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 145, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 146, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 147, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 148, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 149, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 150, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 151, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 152, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 153, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 154, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 155, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 156, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 157, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 158, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 159, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 160, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 161, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 162, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 163, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 164, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 165, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 166, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 167, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 168, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 169, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 170, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 171, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 172, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 173, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 174, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 175, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 176, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 177, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 178, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 179, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 180, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 181, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 182, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 183, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 184, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 185, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 186, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 187, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 188, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 189, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 190, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 191, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 192, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 193, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 194, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 195, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 196, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 197, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 198, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n",
      "Epoch 199, training loss:  nan\n",
      "valid loss nan and accuracy 0.437\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loop(model, epochs=200, lr=3e-4, wd=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826ae50e",
   "metadata": {},
   "source": [
    "### Evaluation WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874fb9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     model.eval()\n",
    "#     output = model.forward(y_).cuda()\n",
    "# output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4cb497",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17698c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusio_matrix(y_test, y_predicted):\n",
    "  cm = confusion_matrix(y_test, y_predicted)\n",
    "  plt.figure(figsize=(8,4))\n",
    "  plt.clf()\n",
    "  plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Wistia)\n",
    "  classNames = ['Cytosol', 'Mitochondria', 'Nuclear', 'Secretory']\n",
    "  plt.title('Confusion Matrix')\n",
    "  plt.ylabel('True label')\n",
    "  plt.xlabel('Predicted label')\n",
    "  tick_marks = np.arange(len(classNames))\n",
    "  plt.xticks(tick_marks, classNames, rotation=45)\n",
    "  plt.yticks(tick_marks, classNames)\n",
    "  \n",
    "  for i in range(4):\n",
    "      for j in range(4):\n",
    "          plt.text(j,i,str(cm[i][j]))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502d81c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusio_matrix(y_val, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80eb294c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
